{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PaddlePaddle实现多层神经网络\n",
    "\n",
    "欢迎大家来到这次实验，在这次实验中我们将使用PaddlePaddle来实现一个多层神经网络，这个多层神经网络包含2个隐藏层，并且在隐藏层中使用到了Relu激活函数，在最后的输出层使用了Softmax激活函数。多层神经网络具有比逻辑回归更强的学习能力，并且更适合解决多分类问题，现在让我们进入实验来看看多层神经网络与逻辑回归之间的差异性吧！\n",
    "\n",
    "** 你将学会 **\n",
    "\n",
    "- 实现一个具有两个隐藏层的神经网络，用于解决多分类问题\n",
    "\n",
    "- 使用batch_norm做数据归一化\n",
    "\n",
    "- 在隐藏层中使用Relu激活函数\n",
    "\n",
    "- 在输出层使用Softmax激活函数\n",
    "\n",
    "- 使用classification_cost\n",
    "\n",
    "- 使用Adam作为优化器\n",
    "\n",
    "现在让我们进入实验吧！\n",
    "\n",
    "## 1 - 引用库\n",
    "\n",
    "首先，载入几个需要用到的库，它们分别是：\n",
    "\n",
    "- numpy：一个python的基本库，用于科学计算\n",
    "- matplotlib.pyplot：用于生成图，在验证模型准确率和展示成本变化趋势时会使用到\n",
    "- paddle.v2：PaddlePaddle深度学习框架\n",
    "- os：在本例中用于获取文件或目录的路径\n",
    "- csv：用于对csv文件的存储和读取等操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import paddle.v2 as paddle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 问题描述： **\n",
    "\n",
    "红酒的品种多样，质量也有高低之分，质量的好坏决定了红酒的价格定位，假设你被聘为一家红酒供应商的红酒质量鉴定专家，红酒供应商给你提供了一些红酒的指标值和评分数据，希望你能从这些数据中学习到红酒的质量鉴定方法。\n",
    "\n",
    "** 你的目标： **\n",
    "\n",
    "构建一个多层神经网络来对红酒质量评分\n",
    "\n",
    "** 数据集分析： **\n",
    "\n",
    "红酒数据集是采集于葡萄牙北部“Vinho Verde”葡萄酒的数据，它是研究Classification/Regression模型训练的经典数据集。这个数据集包含了红白两种葡萄酒的数据，在本实验中采用了红酒数据作为实验数据，红酒的数据包含11个特征值（指标）和一个0-10的评分值（由于隐私等问题，在特征值中不包含价格、品牌等因素，只涵盖了红酒的物理化学性质因素）：\n",
    "\n",
    "输入值：\n",
    "\n",
    "1 - fixed acidity 固定酸度\n",
    "\n",
    "2 - volatile acidity 挥发性酸度\n",
    "\n",
    "3 - citric acid 柠檬酸\n",
    "\n",
    "4 - residual sugar 残糖\n",
    "\n",
    "5 - chlorides 氯化物\n",
    "\n",
    "6 - free sulfur dioxide 自由二氧化硫\n",
    "\n",
    "7 - total sulfur dioxide 总二氧化硫\n",
    "\n",
    "8 - density 密度\n",
    "\n",
    "9 - pH pH值\n",
    "\n",
    "10 - sulphates 硫酸盐\n",
    "\n",
    "11 - alcohol 酒精\n",
    "\n",
    "输出值：\n",
    "\n",
    "12 - quality (0-10的评分) 质量\n",
    "\n",
    "## 2 - 数据预处理\n",
    "\n",
    "** 文件路径 **\n",
    "\n",
    "红酒数据被存储在当前文件夹下的data目录中，data目录中共有两个数据文件，分别是：\n",
    "\n",
    "- winequality-red.csv：红（葡萄）酒数据\n",
    "- winequality-white.csv：白（葡萄）酒数据\n",
    "\n",
    "我们暂时先使用数据量较少的红酒数据来训练模型，当然你可以在完成实验后，使用白（葡萄）酒数据来重新训练或者验证你的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "\n",
    "filename = cur_dir + \"/data/winequality-red.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 载入数据 **\n",
    "\n",
    "首先，我们使用csv.reader()来读取红酒数据，并存入data数组中，输出数据的属性和一组值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed acidity', '\"volatile acidity\"', '\"citric acid\"', '\"residual sugar\"', '\"chlorides\"', '\"free sulfur dioxide\"', '\"total sulfur dioxide\"', '\"density\"', '\"pH\"', '\"sulphates\"', '\"alcohol\"', '\"quality\"'] \n",
      "\n",
      "['7.4', '0.7', '0', '1.9', '0.076', '11', '34', '0.9978', '3.51', '0.56', '9.4', '5']\n"
     ]
    }
   ],
   "source": [
    "with open(filename) as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = []\n",
    "        for row in reader:\n",
    "            data.append([i for i in row[0].split(';')])        \n",
    "            \n",
    "print data[0],\"\\n\"\n",
    "print data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，数据中存储了关于红酒的11类特征值和1个标签值（分数）。\n",
    "\n",
    "** 预处理 **\n",
    "\n",
    "现在让我们对数据进行一些预处理操作。观察上面输出的数据样例，我们发现数据是以字符串的形式存储的，并且第一行数据（data[0]）存储的是属性，而不是具体的数据，所以我们需要去除第一行数据，并且将剩余的数据类型转换为np.float32的numpy数组。这一操作十分简单，只需要使用np.array(<font color=blue>array</font>).astype(<font color=blue>type</font>)即可完成。\n",
    "\n",
    "** 练习： **\n",
    "\n",
    "取出除第一行外的数据，并将数据类型转换为np.float32的numpy数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.4000001    0.69999999   0.           1.89999998   0.076       11.          34.\n",
      "   0.99779999   3.50999999   0.56         9.39999962   5.        ]\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data[1:]).astype(np.float32)\n",
    "\n",
    "print data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 期望输出： **\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "[  7.4000001    0.69999999   0.           1.89999998   0.076       11.          34.\n",
    "   0.99779999   3.50999999   0.56         9.39999962   5.        ]\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "想要训练一个模型，我们首先需要将原始数据集切分为训练数据集(train set)和训练数据集(test set)，定义一个$ratio$变量，它是一个介于$[0,1]$区间的标量，代表着训练数据占总数据的比重，例如设置$ratio=0.8$，它表示训练数据占总数据量的八成，如果data_num代表数据总数，那么ratio * data_num等于训练集数量。\n",
    "\n",
    "** 练习： **\n",
    "\n",
    "将数据划分为训练数据集和测试数据集（因为数据量较少，建议将ratio设置为0.8左右较为合理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set shape: (1279, 12)\n",
      "test set shape: (320, 12)\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.8\n",
    "data_num = len(data)\n",
    "slice = int(ratio * data_num)\n",
    "train_set = data[:slice]\n",
    "test_set = data[slice:]\n",
    "\n",
    "print \"train set shape:\", train_set.shape\n",
    "print \"test set shape:\", test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果将ratio设置为0.8则\n",
    "\n",
    "** 期望输出： **\n",
    "\n",
    "<table style=\"width:20%\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            ** train set shape ** \n",
    "        </td>\n",
    "        <td>\n",
    "            (1278, 12)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            ** test set shape ** \n",
    "        </td>\n",
    "        <td>\n",
    "            (320, 12)\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - 构造reader\n",
    "\n",
    "在逻辑回归的实验中我们介绍了reader()的构造方法以及生成器的概念，在这里我们同样构造一个read_data()函数来读取训练数据集train_set或者测试数据集test_set。它的具体实现是在read_data()函数内部构造一个reader()，使用yield关键字来让reader()成为一个Generator（生成器）。\n",
    "\n",
    "** 注意：** 由于红酒的品质鉴定属于多分类问题（将结果划分为0-10的离散整数），所以我们将标签值（评分）的数据类型转化为integer类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], 1)\n",
      "([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0)\n"
     ]
    }
   ],
   "source": [
    "def read_data(data):\n",
    "    def reader():\n",
    "        for d in data:\n",
    "            yield d[:-1], int(d[-1])\n",
    "    return reader\n",
    "\n",
    "test_arr = [[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "            ]\n",
    "\n",
    "reader = read_data(test_arr)\n",
    "for d in reader():\n",
    "    print d "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 期望输出： **\n",
    "\n",
    "<table style=\"width:30%;text-align:center\" >\n",
    "    <tr>\n",
    "        <td>\n",
    "            ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], 1)\n",
    "            ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0)\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - 训练过程\n",
    "\n",
    "完成了数据的预处理工作并构造了read_data()来读取数据，接下来将进入模型的训练过程，使用PaddlePaddle来构造可训练的Logistic回归模型，关键步骤如下：\n",
    "\n",
    "- 初始化\n",
    "\n",
    "- 配置网络结构和设置参数\n",
    "    - 配置网络结构\n",
    "    - 定义损失函数cost\n",
    "    - 创建parameters\n",
    "    - 定义优化器optimizer\n",
    "\n",
    "- 模型训练\n",
    "\n",
    "- 模型检验\n",
    "\n",
    "- 预测\n",
    "\n",
    "- 绘制学习曲线\n",
    "\n",
    "** （1）初始化 **\n",
    "\n",
    "首先进行最基本的初始化操作，在PaddlePaddle中使用paddle.init(use_gpu=False, trainer_count=1)来进行初始化：\n",
    "\n",
    "- use_gpu=False表示不使用gpu进行训练\n",
    "\n",
    "- trainer_count=1表示仅使用一个训练器进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化\n",
    "paddle.init(trainer_count=1, use_gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** （2）配置网络结构和设置参数 **\n",
    "\n",
    "** 网络结构： **\n",
    "\n",
    "了解一下我们即将要配置的网络结构，如图所示，它的基本结构是输入层、两个隐藏层和输出层，两个隐藏层使用ReLU激活函数，输出层使用Softmax激活函数（多分类），除此之外，在输入层之后添加一层Batch Normalization对数据进行归一化处理。\n",
    "\n",
    "<img src=\"image/structure.png\" width=\"500px\">\n",
    "\n",
    "下面我们简单介绍一下网络结构中使用到的ReLU以及Softmax激活函数：\n",
    "\n",
    "** ReLU(Rectified linear unit) **\n",
    "\n",
    "ReLU激活函数通常比sigmoid和tanh激活函数的表现更好，其中一个原因是sigmoid和tanh在两端的饱和阶段梯度接近0，容易造成梯度消失问题(Vanishing Gradient Problem)，尤其是在深度网络中更加明显，而ReLU在非负区间的梯度为常数，因此不存在梯度消失问题，使得模型的收敛速度维持在一个稳定状态。我们在两个隐藏层上使用ReLU作为激活函数。\n",
    "\n",
    "<img src=\"image/relu.png\" width=\"200px\">\n",
    "\n",
    "** Softmax **\n",
    "\n",
    "Softmax是神经网络中另一种激活函数，计算输出层的值。主要用于神经网络最后一层，作为输出层进行多分类，是逻辑回归二分类的推广。\n",
    "\n",
    "Sigmoid将结果值映射到$[0,1]$区间，用来做二分类。 而Softmax的函数形式如下，把一个k维的向量（y1,y2,y3,y4 … yk.）映射成（a1,a2,a3 … ak.），其中ai介于区间$[0,1]$，根据ai的大小来进行多分类的任务，如取权重最大的一维。\n",
    "\n",
    "<img src=\"image/softmax.png\" width=\"250px\">\n",
    "\n",
    "\n",
    "** 配置网络结构 **\n",
    "\n",
    "现在我们已经了解了网络结构，开始着手配置吧！\n",
    "\n",
    "** 练习：** 使用PaddlePaddle配置网络结构\n",
    "\n",
    "** 输入层： **\n",
    "\n",
    "我们可以定义x=paddle.layer.data(name=”x”, type=paddle.data_type.dense_vector(data_dim))来表示生成一个数据输入层，名称为“x”，数据类型为data_dim维向量；\n",
    "\n",
    "在定义输入层之前，我们需要计算数据的特征维度data_dim。\n",
    "\n",
    "** Batch normalization层： **\n",
    "\n",
    "我们可以定义norm1 = paddle.layer.batch_norm(input=x, act=paddle.activation.Relu())表示生成一个Batch normalization层，输入数据为x，激活函数为Relu()；\n",
    "\n",
    "** 隐藏层： **\n",
    "\n",
    "我们定义两个隐藏层h1和h2，以h1为例，定义h1=paddle.layer.fc(input=norm1, size=32, act=paddle.activation.Relu())，表示生成一个全连接层类型的隐藏层，输入数据为norm1，神经元个数为32，激活函数为Relu()；\n",
    "\n",
    "** 输出层： **\n",
    "\n",
    "我们可以定义predict=paddle.layer.fc(input=h2, size=10, act=paddle.activation.Softmax())表示生成一个全连接层，输入数据为h2，输出结果共有10个，分别表示十个不同的分类，激活函数为Softmax()；\n",
    "\n",
    "** 标签层 **\n",
    "\n",
    "我们可以定义label = paddle.layer.data(name='label', type=paddle.data_type.integer_value(10))表示生成一个数据层，名称为“label”，数据类型为包含0-9的整型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = train_set.shape[1] - 1\n",
    "\n",
    "x = paddle.layer.data(name='x', type=paddle.data_type.dense_vector(data_dim))\n",
    "\n",
    "norm1 = paddle.layer.batch_norm(input=x, act=paddle.activation.Relu())\n",
    "\n",
    "h1 = paddle.layer.fc(input=norm1, size=32, act=paddle.activation.Relu())\n",
    "\n",
    "h2 = paddle.layer.fc(input=h1, size=16, act=paddle.activation.Relu())\n",
    "\n",
    "predict = paddle.layer.fc(input=h2, size=10, act=paddle.activation.Softmax())\n",
    "\n",
    "label = paddle.layer.data(name='label', type=paddle.data_type.integer_value(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 定义损失函数 **\n",
    "\n",
    "在配置网络结构之后，我们需要定义一个损失函数来计算梯度并优化参数，在这里我们可以使用PaddlePaddle提供的用于多分类的损失函数，定义cost = paddle.layer.classification_cost(input=predict, label=label)，使用predict与label计算成本。\n",
    "\n",
    "** 练习： **\n",
    "\n",
    "定义多分类损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "### START CODE HERE ### (≈ 2 lines of code)\n",
    "cost = paddle.layer.classification_cost(input=predict, label=label)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 创建parameters **\n",
    "\n",
    "PaddlePaddle中提供了接口paddle.parameters.create(cost)来创建和初始化参数，参数cost表示基于我们刚刚创建的cost损失函数来创建和初始化参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建parameters\n",
    "### START CODE HERE ### (≈ 1 lines of code)\n",
    "parameters = paddle.parameters.create(cost)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** optimizer **\n",
    "\n",
    "参数创建完成后，我们需要定义一个优化器optimizer，在逻辑回归实验中我们使用了Momentum作为优化器，在这里我们尝试使用Adam来作为优化器，它的计算公式如下：\n",
    "\n",
    "$$\\begin{split}m(w, t) & = \\beta_1 m(w, t-1) + (1 - \\beta_1) \\nabla Q_i(w) \\\\ v(w, t) & = \\beta_2 v(w, t-1) + (1 - \\beta_2)(\\nabla Q_i(w)) ^2 \\\\ w & = w - \\frac{\\eta m(w, t)}{\\sqrt{v(w,t) + \\epsilon}}\\end{split}$$\n",
    "\n",
    "Adam是一种常用的、效果良好的自适应学习率调整优化算法，通常只需要将参数设置为beta1=0.9，beta2=0.999，epsilon=1e-08，不需要作修改即可让模型产生好的收敛效果。在PaddlePaddle中可以使用接口paddle.optimizer.Adam()来创建Adam优化器。\n",
    "\n",
    "** 练习： **\n",
    "\n",
    "创建Adam优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建optimizer\n",
    "\n",
    "optimizer = paddle.optimizer.Adam(\n",
    "    beta1=0.9,\n",
    "    beta2=0.999,\n",
    "    epsilon=1e-08\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 其它配置 **\n",
    "\n",
    "feeding={‘x’:0, ‘label’:1}是数据层名称和数组索引的映射，用于在训练时输入数据，lists数组用于保存pass_id, train set cost, test set cost等信息。\n",
    "\n",
    "最后定义函数event_handler(event)用于事件处理，设置每100次迭代，利用测试数据来计算当前的test set cost，并将pass_id，train set cost和test set cost输出并存储至lists中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeding = {\n",
    "    'x': 0,\n",
    "    'label': 1\n",
    "}\n",
    "\n",
    "lists = []\n",
    "\n",
    "def event_handler(event):\n",
    "    if isinstance(event, paddle.event.EndIteration):\n",
    "        if event.pass_id % 100 == 0 and event.batch_id == 0:\n",
    "            result = trainer.test(reader=paddle.batch(\n",
    "                read_data(test_set), batch_size=128))\n",
    "            print(\"pass {}, batch_id {}, train set cost {}, test set cost {}\").format(event.pass_id, event.batch_id, event.cost, result.cost)\n",
    "            lists.append((event.pass_id, event.cost, result.cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 模型训练 **\n",
    "\n",
    "在逻辑回归实验中我们介绍了trainer的构建以及训练过程的参数配置，相信大家已经理解并学会如何配置buf_size/batch_size/num_passes等参数。\n",
    "\n",
    "** 练习：**\n",
    "\n",
    "定义trainer并开始训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass 0, batch_id 0, train set cost 2.281031847, test set cost 8.64661445618\n",
      "pass 100, batch_id 0, train set cost 0.864398658276, test set cost 1.02421370745\n",
      "pass 200, batch_id 0, train set cost 0.777176737785, test set cost 1.04286775589\n",
      "pass 300, batch_id 0, train set cost 0.739849030972, test set cost 1.07083622217\n",
      "pass 400, batch_id 0, train set cost 0.579931437969, test set cost 1.12942759991\n",
      "pass 500, batch_id 0, train set cost 0.834986150265, test set cost 1.17374812365\n",
      "pass 600, batch_id 0, train set cost 0.66029715538, test set cost 1.21673964262\n",
      "pass 700, batch_id 0, train set cost 0.630392193794, test set cost 1.25913171768\n",
      "pass 800, batch_id 0, train set cost 0.664287745953, test set cost 1.31677081585\n",
      "pass 900, batch_id 0, train set cost 0.623641610146, test set cost 1.38956637383\n"
     ]
    }
   ],
   "source": [
    "trainer = paddle.trainer.SGD(\n",
    "    cost=cost, parameters=parameters, update_equation=optimizer\n",
    ")\n",
    "\n",
    "trainer.train(\n",
    "    reader=paddle.batch(\n",
    "        paddle.reader.shuffle(read_data(train_set), buf_size=5000),\n",
    "        batch_size=128\n",
    "    ),\n",
    "    feeding=feeding,\n",
    "    event_handler=event_handler,\n",
    "    num_passes=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best pass is 100, training Avgcost is 0.864398658276, testing Avgcost is 1.02421370745\n"
     ]
    }
   ],
   "source": [
    "# 查看训练过程中的最佳pass\n",
    "best = sorted(lists, key=lambda list: float(list[2]))[0]\n",
    "print(\"Best pass is {}, training Avgcost is {}, testing Avgcost is {}\").format(best[0], best[1], best[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 模型检验 **\n",
    "\n",
    "模型训练完成后，接下来检验模型的准确率。\n",
    "\n",
    "利用paddle.infer()来进行预测，参数output_layer表示输出层，参数parameters表示模型参数，参数input表示输入的测试数据。\n",
    "\n",
    "** 练习：**\n",
    "\n",
    "- 使用paddle.infer()进行预测\n",
    "\n",
    "- 输出部分红酒的label和预测评分进行对比\n",
    "\n",
    "** 技巧： **\n",
    "\n",
    "预测结果probs是（num_test, 10）的numpy数组，每个测试样例的输出结果为10个数字，分别代表红酒的评分是0-9的可能性，我们取出可能性最大的值作为最后的评分，所以我们可以使用lab=np.argsort(-probs)来做降序排序，将可能性最大的评分放在最前头，这样lab[i][0]则表示第i瓶红酒的最终评分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs shape: (320, 10)\n",
      "probs sample: [  3.59487516e-04   1.54166482e-04   3.75506788e-04   2.31721625e-03\n",
      "   7.76880002e-03   9.91239324e-02   6.52422309e-01   1.98356614e-01\n",
      "   3.81874442e-02   9.34517360e-04]\n"
     ]
    }
   ],
   "source": [
    "data_creater = read_data(test_set)\n",
    "\n",
    "test_x = []\n",
    "test_y = []\n",
    "for item in data_creater():\n",
    "    test_x.append((item[0], ))\n",
    "    test_y.append(item[1])\n",
    "\n",
    "probs = paddle.infer(\n",
    "        output_layer=predict, parameters=parameters, input=test_x)\n",
    "\n",
    "print \"probs shape:\", probs.shape\n",
    "print \"probs sample:\", probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 6, predict: 7\n",
      "label: 6, predict: 6\n",
      "label: 6, predict: 6\n",
      "label: 6, predict: 6\n",
      "label: 5, predict: 6\n",
      "label: 6, predict: 5\n",
      "label: 6, predict: 5\n",
      "label: 6, predict: 6\n",
      "label: 6, predict: 5\n",
      "label: 5, predict: 5\n",
      "label: 5, predict: 5\n",
      "label: 6, predict: 5\n",
      "label: 6, predict: 6\n",
      "label: 7, predict: 6\n",
      "label: 5, predict: 4\n",
      "label: 6, predict: 6\n",
      "label: 5, predict: 5\n",
      "label: 5, predict: 5\n",
      "label: 6, predict: 6\n",
      "label: 6, predict: 6\n"
     ]
    }
   ],
   "source": [
    "lab = np.argsort(-probs)\n",
    "\n",
    "for i in range(20):\n",
    "    print(\"label: {}, predict: {}\").format(lab[i][0], test_y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们输出了20瓶红酒的label和predict值，可以看到模型对红酒数据的学习效果还算不错，现在可以为红酒供应商进行大批量的红酒质量鉴定工作了。恭喜你完成了更加复杂的深度学习实验，同样，你可以参考官方[PaddlePaddle文档](http://paddlepaddle.org/docs/develop/documentation/zh/getstarted/index_cn.html)来修改模型，尝试得到更好的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 学习曲线 **\n",
    "\n",
    "接下来我们利用之前保存的lists数据来输出成本的变化情况，利用学习曲线对模型进行分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f134108c8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "costs = np.squeeze([list[1] for list in lists])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，模型在最初收敛很快，但在学习后期出现波动，但总体为下降趋势，这可能是因为Adam的缺点，即在训练后期引起学习率的震荡，导致模型无法收敛，通常我们可以在训练后期改用SGD来训练以达到更好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - 总结\n",
    "\n",
    "通过这个练习我们应该记住：\n",
    "\n",
    "1. ReLU激活函数比tanh和sigmoid更适合深层神经网络，因为它不存在梯度消失问题\n",
    "\n",
    "2. 使用Batch Normalization能够加速模型训练\n",
    "\n",
    "3. 利用Softmax可以解决多分类问题\n",
    "\n",
    "4. Adam是一种常用的、效果良好的自适应学习率调整优化算法，通常使用它能够得到不错的学习效果。\n",
    "\n",
    "\n",
    "至此，我们完成了比逻辑回归模型稍复杂的多层神经网络模型的配置和训练，不难发现，在PaddlePaddle中，只需要通过简单地叠加或删除数据层、连接层等，就可以轻易地改变模型结构，自由度很高，大家可以尝试使用更多层数的神经网络或者改变每一层的神经元个数来修改模型，在调试中加深对深度学习的理解和PaddlePaddle框架的熟悉度。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
